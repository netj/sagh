#!/usr/bin/env python
'''
Input: Path to pickled DF-bipartite graph
Output: Pickled Dictionary containing Similarity between P-P and D-D
'''
from multiprocessing import Pool, Process
import pickle
import sys,os
import math
import sagh

numProcesses = int(os.environ['SAGH_NUMCORES']) if 'SAGH_NUMCORES' in os.environ else 4

graph = None
lDevelopers = []
lFiles = []
nodeLists = {
        "Developers": lDevelopers,
        "Files": lFiles,
        }
nodeListsOrder = ["Developers", "Files"]
score = None

def f((i,name)):
    lst = nodeLists[name]
    u = lst[i]
    newScores = {}
    hasConverged = True
    for v in lst[i+1:]:
        c = 0.8
        neighbors_u = graph.neighbors(u)
        neighbors_v = graph.neighbors(v)
        count1 = len(neighbors_u)
        count2 = len(neighbors_v) 
        if(count1==0 or count2==0): 
            continue
        
        total = sum(score[(f1,f2)] if (f1,f2) in score else 0.0
                for f1 in neighbors_u for f2 in neighbors_v)
        
        oldScore = score[(u,v)] if (u,v) in score else 0.0
        newScore = float(c*total)/float(count1*count2)

        if (math.fabs(oldScore - newScore) > epsilon):
            newScores[(u,v)]=newScore
            hasConverged = False

    return hasConverged, newScores

#def printScores(ns):
#    for i in range(len(ns)):
#        for j in range(i+1, len(ns)):
#           print >>sys.stderr, "%s\t%s\t%f" % (ns[i],ns[j], score[(ns[i],ns[j])] + score[(ns[j],ns[i])])

if __name__ == '__main__':
    epsilon = 1e-4
    graphFileName = sagh.suffixWithArgs('user-file-graph', 1)
    tableFileName = sagh.suffixWithArgs('user-user-simrank', 1)

    # debugging
    #import multiprocessing, logging
    #logger = multiprocessing.log_to_stderr()
    #logger.setLevel(multiprocessing.SUBDEBUG)

    #if len(sys.argv) != 2:
    #    print 'usage : DF-graphCreate.py <path_to_DFgraph> \n'
    #    sys.exit(1)
    #    
    # Reading the input DF-graph
    #graph = pickle.load(open(sys.argv[1]))
    print >>sys.stderr, "loading %s" % graphFileName
    graph = pickle.load(open(graphFileName))
    #print 'nodes',len(graph.nodes()),graph.nodes()
    #print 'edges',len(graph.edges()),graph.edges()
    #sys.exit(0)
    print >>sys.stderr, "done loading"

    score = {}
    for node in graph.nodes():
        score[(node,node)] = 1.0

    for node in graph.nodes(data=True):
        if (node[1]['type']=='Developer'): lDevelopers.append(node[0])
        else: lFiles.append(node[0])

    #print len(lDevelopers), lDevelopers
    #print len(lFiles), lFiles
    #
    #print lDevelopers
    #print lFiles

    T = 20
    print >>sys.stderr, "#Developers=%d, #Files=%d" % (len(lDevelopers), len(lFiles))
    hasConverged = False
    convergedAfterIteration = -1

    iteration = -1
    for iteration in range(T):
        print >>sys.stderr, iteration, 'beginning iteration'

        flag = True
        for name in nodeListsOrder:
            lst = nodeLists[name]
            print >>sys.stderr, iteration, 'creating pool for computing', name
            pool = Pool(processes=numProcesses)
            print >>sys.stderr, iteration, 'starting computation with pool for', name
            result = pool.map(f, [(i,name) for i in range(len(lst))])
            pool.close()
            pool.join()
            print >>sys.stderr, iteration, 'pool has computed, unzipping for', name
            flags, newScores = zip(*result)
            print >>sys.stderr, iteration, 'merging scores for', name
            for d in newScores: score.update(d)
            flag = all(flags) and flag
            print >>sys.stderr, iteration, 'done merging', name
        
        if(flag):
            hasConverged = True
            convergedAfterIteration = iteration
            print >>sys.stderr, 'Convergence in ', iteration, 'iterations\n'
            break

        # dumping intermediate score table to disk
        print >>sys.stderr, "storing %s" % tableFileName
        pickle.dump(score, open(tableFileName, 'w'))

    #for i in range(len(lFiles)):
    #    for j in range(i+1,len(lFiles)):
    #        print (lFiles[i],lFiles[j]), '--->', score[(lFiles[i],lFiles[j])]
        
    if hasConverged:
        print >>sys.stderr, 'Converged in ', convergedAfterIteration, 'iterations\n'

    # store the compact version of simrank scores (of developers only)
    print >>sys.stderr, "storing %s" % tableFileName
    pickle.dump(score, open(tableFileName, 'w'))

    # output in textual form
    for i,u in enumerate(lDevelopers):
        for v in lDevelopers[i+1:]:
            if (u,v) in score:
                print graph.node_labels_inv[u], graph.node_labels_inv[v], score[(u,v)]

