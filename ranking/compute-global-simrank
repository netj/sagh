#!/usr/bin/env python
'''
Input: Path to pickled DF-bipartite graph
Output: Pickled Dictionary containing Similarity between P-P and D-D
'''
from multiprocessing import Pool, Process
from collections import defaultdict
import pickle
import sys,os
import math
import sagh

numProcesses = int(os.environ['SAGH_NUMCORES']) if 'SAGH_NUMCORES' in os.environ else 4

graph = None
lDevelopers = None
lFiles = None
score = None

def f((i,step)):

    newScores = {}

    if step == 0:
        lst = lDevelopers
    else:
        lst = lFiles

    hasConverged = True

    for j in range(i+1,len(lst)):
        c = 0.8
        count1 = len(graph.neighbors(lst[i]))
        count2 = len(graph.neighbors(lst[j])) 
        if(count1==0 or count2==0): 
            continue
        
        total = 0.0
        for f1 in graph.neighbors(lst[i]):
            for f2 in graph.neighbors(lst[j]):
                total += score[(f1,f2)]
        
        newScore = float(c*total)/float(count1*count2)

        if (math.fabs(score[(lst[i],lst[j])] - newScore) > epsilon):
            newScores[(lst[i],lst[j])]=newScore
            hasConverged = False

    return hasConverged, newScores

def printScores(ns):
    for i in range(len(ns)):
        for j in range(i+1, len(ns)):
           print >>sys.stderr, "%s\t%s\t%f" % (ns[i],ns[j], score[(ns[i],ns[j])] + score[(ns[j],ns[i])])

if __name__ == '__main__':
    epsilon = 1e-4
    graphFileName = sagh.suffixWithArgs('user-file-graph', 1)
    tableFileName = sagh.suffixWithArgs('user-user-simrank', 1)

    # debugging
    #import multiprocessing, logging
    #logger = multiprocessing.log_to_stderr()
    #logger.setLevel(multiprocessing.SUBDEBUG)

    #if len(sys.argv) != 2:
    #    print 'usage : DF-graphCreate.py <path_to_DFgraph> \n'
    #    sys.exit(1)
    #    
    # Reading the input DF-graph
    #graph = pickle.load(open(sys.argv[1]))
    print >>sys.stderr, "loading %s" % graphFileName
    graph = pickle.load(open(graphFileName))
    #print 'nodes',len(graph.nodes()),graph.nodes()
    #print 'edges',len(graph.edges()),graph.edges()
    #sys.exit(0)
    print >>sys.stderr, "done loading"

    score = defaultdict(float)

    for node in graph.nodes():
        score[(node,node)] = 1.0

    lDevelopers = []
    lFiles = []

    for node in graph.nodes(data=True):
        if (node[1]['type']=='Developer'): lDevelopers.append(node[0])
        else: lFiles.append(node[0])

    #print len(lDevelopers), lDevelopers
    #print len(lFiles), lFiles
    #
    #print lDevelopers
    #print lFiles

    T = 20
    print >>sys.stderr, "#Developers=%d, #Files=%d" % (len(lDevelopers), len(lFiles))
    hasConverged = False
    convergedAfterIteration = -1

    iteration = -1
    for iteration in range(T):
        print >>sys.stderr, iteration, 'beginning iteration'

        flag = True
        for step, (name,lst) in enumerate([("Developers",lDevelopers), ("Files",lFiles)]):
            print >>sys.stderr, iteration, 'creating pool for computing', name
            pool = Pool(processes=numProcesses)
            print >>sys.stderr, iteration, 'starting computation with pool for', name
            result = pool.map(f, [(i,step) for i in range(len(lst))])
            pool.close()
            pool.join()
            print >>sys.stderr, iteration, 'pool has computed, unzipping for', name
            flags, newScores = zip(*result)
            print >>sys.stderr, iteration, 'merging scores for', name
            for d in newScores: score.update(d)
            flag = all(flags) and flag
            print >>sys.stderr, iteration, 'done merging', name
        
        if(flag):
            hasConverged = True
            convergedAfterIteration = iteration
            print >>sys.stderr, 'Convergence in ', iteration, 'iterations\n'
            break

        # dumping intermediate score table to disk
        print >>sys.stderr, "storing %s" % tableFileName
        pickle.dump(score, open(tableFileName, 'w'))

    #for i in range(len(lFiles)):
    #    for j in range(i+1,len(lFiles)):
    #        print (lFiles[i],lFiles[j]), '--->', score[(lFiles[i],lFiles[j])]
        
    if hasConverged:
        print >>sys.stderr, 'Converged in ', convergedAfterIteration, 'iterations\n'

    # store the compact version of simrank scores (of developers only)
    print >>sys.stderr, "storing %s" % tableFileName
    pickle.dump(score, open(tableFileName, 'w'))

    # output in textual form
    for i in range(len(lDevelopers)):
        for j in range(i+1, len(lDevelopers)):
            print graph.node_labels_inv[lDevelopers[i]], graph.node_labels_inv[lDevelopers[j]], score[(lDevelopers[i],lDevelopers[j])]

